<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        div.padded {
            padding-top: 0px;
            padding-right: 100px;
            padding-bottom: 0.25in;
            padding-left: 100px;
        }
    </style>
    <title>Aryan Agrawal, Ruslana Yurtyn, Aadith Srinivasan, Tarun Singh | CS 184</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
    <br />
    <h1 align="middle">Final Project Writeup</h1>
    <h2 align="middle">Aryan Agrawal, Ruslana Yurtyn, Aadith Srinivasan, Tarun Singh</h2>


    <div class="padded">
        <p>
            As we stated in the project proposal, our goal for this project is to create a program that
            takes a point cloud input and efficiently outputs a mesh representation of that point cloud.
            To do this, we are implementing the ball-pivoting algorithm for surface reconstruction presented 
            in this paper: https://vgc.poly.edu/~csilva/papers/tvcg99.pdf
        </p>
        <p>
            Much of the work for this project has been in designing and implementing the processing pipeline. Questions 
            we had to answer included what format would we represent our inputs in, and how do we get them? How do we
            represent our outputs, and how do we visualize them? We determined that the best way for us to get our inputs,
            specicially, a point cloud (which consists of a set of vertices defined by their positions and their estimated normals), is 
            to convert from existing ply files. The ply file format is defined in the Stanford 3D Scanning Repository (http://graphics.stanford.edu/data/3Dscanrep/).
            As we parsed the format of these files, we realized that the standard ply format contains more information than we need, but also doesn't explicitly
            have all the info we need. Specifically, we can get the vertex positions from the ply file, but we have to calculate the normals ourselves.
        </p>
        <p>
            As you can see in the submitted video, much of the code we've written so far had to do with parsing our inputs, calculating 
            estimated surface normals for each vertex, and creating our own file format to represent the point cloud (vertices and their estimated normals).
            We've also begun implementing the algorithm itself, with create_voxels creating a map that groups together vertices in the same spatial "neighborhood" for 
            faster lookup, and a function that calculates a proper ro value for running BPA.
        </p>
        <p>
            So far everything is going pretty much to plan. Our next steps are to finish find_seed_triangle so we can write the iterative portion of BPA, and put together all the 
            pieces. There's some more unit testing to be done to ensure that our normals are all calculated correctly, but we're definitely on schedule to reach our goals and 
            feeling confident that we have time to finish (while allowing time for some debugging).
        </p>

        <p>
            Below are links to our milestone video and milestone slides. On the milestone google form we've submitted some screenshots of additional code we've written since recording
            our milestone video. Thanks!
        </p>

        <h2 align="middle">Milestone Video Link</h2>
        <p>
            https://drive.google.com/file/d/1s04M29lyaCn-SoE6ma7KrdkSnmha3pgu/view?usp=sharing
        </p>

        <h2 align="middle">Slides Link</h2>
        <p>
            https://docs.google.com/presentation/d/170dOdePUvmDF7bQ0LBY35QG5Vf1_wtLGZ8BRDmjXzuE/edit?usp=sharing
        </p>
    </div>
</body>
</html>